Chapter 28

Locks

Essential problem, we want to execute atomically but interrupts on single processor doesnt let us
lock solves this ^
This mainly goes around critical sections

#28.1# Locks, The Basic Idea
Critical section refered to is 
	
	[c]
	balance = balance + 1;
	[end]
	want to keep it simple for now but has a lot of complications poss 

We can add a lock around the section
[c]
1 lock_t mutex; // some globally-allocated lock ’mutex’
2 ...
3 lock(&mutex);
4 balance = balance + 1;
5 unlock(&mutex);
[end]

A lock is just a variable (in this case mutex)
- holds state of lock at a given time
- available or acquired(open or closed)

Essentially, call the lock() function and if mutex is available then can enter critical section
- but if acquired, lock will not return until it can aquire 
- !this is how locks work! not just by checking the value, but not allowing thread execution

#28.2# Pthread Locks
Pthread uses mutex, version below
[c]
1 pthread_mutex_t lock = PTHREAD_MUTEX_INITIALIZER;
2
3 Pthread_mutex_lock(&lock); // wrapper for pthread_mutex_lock()
4 balance = balance + 1;
5 Pthread_mutex_unlock(&lock);
[end]

coarse grained: locking strategy that uses one big lock every time any critical section is accessed
fine grained: locking strategy to have different locks for different data

#28.3# Building a Lock
We can use hardware primitives to help us out

#28.4# Evaluating Locks 
How to evaluate locks
1) Does the lock provide mutual exclusion?
- prevent multiple threads from accessing critical section
2) Fairness
- Does each thread going for the lock have a fair shot at acquiring
- Does any thread starve?
3) Performance
- what is the overhead of a single thread grabbing the lock vs. multiple

#28.5# Controlling interrupts
Earliest implementation, ignore interrupts for critical section
- Pro
	- gives us rough atomicity
- Con 
	- Forces us to make every calling thread have a priveleged operation
	- Trust that wont abuse all of the hardware instructions
	- This does not work on multiprocessors 
		- threads could enter critical section on other processors 
	- losing interrupts
	- very inefficient code

First Attempt, A Simple Flag
[c]
1 typedef struct __lock_t { int flag; } lock_t;
2
3 void init(lock_t *mutex) {
4 // 0 -> lock is available, 1 -> held
5 mutex->flag = 0;
6 }
7
8 void lock(lock_t *mutex) {
9 while (mutex->flag == 1) // TEST the flag
10 ; // spin-wait (do nothing)
11 mutex->flag = 1; // now SET it!
12 }
13
14 void unlock(lock_t *mutex) {
15 mutex->flag = 0;
16 }
[end]

#28.6# Test and Set (Atomic Exchange)
Since Disabling interrupt doesnt work on multiprocessors
- invented hardware support for locking

test and set instruction/atomic exchange comes in
- simplest way to hardware support
- example of failed attempt, use flag variable to denote flag held or not

1st Attempt) Use flag variable to inidicate if someone has possession of the lock
- If another thread tries to call lock() will spin-wait

Problems, correctness and performance 
1) doesn't really do mutual exclusion
2) spin-waiting is high tax, inefficient. 

#28.7# Building a Working Spin Lock 
The test-and-set instruction:
[c]
1 int TestAndSet(int *old_ptr, int new) {
2 int old = *old_ptr; // fetch old value at old_ptr
3 *old_ptr = new; // store ’new’ into old_ptr
4 return old; // return the old value
5 }
[end]

^ returns old value from ptr and updates that value to new
These operations have to be performed atomically 

"test and set" because
tests old value while simultaneously setting memory location to new value. 
- this should be enough to build a simple spin lock 

implementation of simple spin lock using test-and-set
[c]
1 typedef struct __lock_t {
2 int flag;
3 } lock_t;
4
5 void init(lock_t *lock) {
6 // 0 indicates that lock is available, 1 that it is held
7 lock->flag = 0;
8 }
9
10 void lock(lock_t *lock) {
11 while (TestAndSet(&lock->flag, 1) == 1)
12 ; // spin-wait (do nothing)
13 }
14
15 void unlock(lock_t *lock) {
16 lock->flag = 0;
17 }
[end]

By making both the test (of the old lock value) and set (of the new value) a single atomic operation, we ensure that only one thread acquires the lock.
- basis of mutual exclusion primitives

Spin lock 
- simplest lock, just uses CPU cycles until lock is available
- requires preemptive scheduler, interrupts via timer 

#28.8# Evaluating Spin Locks
correctness: does it provide mutual exclusion?
- yes, only ever one thread entering section

fairness: Can you guarantee a waiting thread will eventually enter section?
- No fairness guarantees. Sad!

performance: Does it go fast?
^ this is a little hard
Single CPU case 
- performance overhead is your worst enemy 
- ends up wasting a lot of cpu cycles 
Multi CPU works p well since can spin on different ones

#28.9# Compare and Swap
[c]
1 int CompareAndSwap(int *ptr, int expected, int new) {
2 int actual = *ptr;
3 if (actual == expected)
4 *ptr = new;
5 return actual;
6 }
[end]
Checks if address pointed to ptr is == expected, then update memory with new value
Can build lock from this
[c]
1 void lock(lock_t *lock) {
2 while (CompareAndSwap(&lock->flag, 0, 1) == 1)
3 ; // spin
4 }
[end]

Actual code in C
[c]
1 char CompareAndSwap(int *ptr, int old, int new) {
2 unsigned char ret;
3
4 // Note that sete sets a ’byte’ not the word
5 __asm__ __volatile__ (
6 " lock\n"
7 " cmpxchgl %2,%1\n"
8 " sete %0\n"
9 : "=q" (ret), "=m" (*ptr)
10 : "r" (new), "m" (*ptr), "a" (old)
11 : "memory");
12 return ret;
13 }
[end]

#28.10# Load-Linked and Store-Conditional
Load Linked: basically a standard load function, but checks if any intervening store occurs before updating value
Store Conditional: Only writes to memory if memory has not been tampered with on a certain Conditional

[c]
1 void lock(lock_t *lock) {
2 while (1) {
3 while (LoadLinked(&lock->flag) == 1)
4 ; // spin until it’s zero
5 if (StoreConditional(&lock->flag, 1) == 1)
6 return; // if set-it-to-1 was a success: all done
7 // otherwise: try it all over again
8 	}
9 }
10
11 void unlock(lock_t *lock) {
12 lock->flag = 0;
13 }
[end]

#28.11# Fetch-and-Add
Atomic instruction to increment and get old value of memory address
C Pseudo Code 
[c]
1 int FetchAndAdd(int *ptr) {
2 int old = *ptr;
3 *ptr = old + 1;
4 return old;
5 }
1 typedef struct __lock_t {
2 int ticket;
3 int turn;
4 } lock_t;
5
6 void lock_init(lock_t *lock) {
7 lock->ticket = 0;
8 lock->turn = 0;
9 }
10
11 void lock(lock_t *lock) {
12 int myturn = FetchAndAdd(&lock->ticket);
13 while (lock->turn != myturn)
14 ; // spin
15 }
16
17 void unlock(lock_t *lock) {
18 lock->turn = lock->turn + 1;
19 }
[end]

use this to build a ticket lock
Basically every thread assigned a ticket, keep atomically moving that value and when your ticket is up you get the critical section
guarantees all threads get a chance in the queue

#28.12# Too Much Spinning: What Now?
Spin spin spin how to solve?

#28.13# A Simple Approach: Just Yield, Baby
When about to spin, just give up to another thread 

Important stuff, changes thread from running to ready
- essentially it deschedules itself
- Problems, cost of context switching still high and starvation 

#28.14# Using Queues: Sleeping Instead Of Spinning
Implement a queue to make it easier for starvation to stop

#28.15# Different OS, Different Support 
Linux futex, use to sleep and wake as need be
futex_wake(mutex) 

#28.16# Two-Phase Locks 
Two-Phae Lock: Spinning can be useful, if lock is about to be released
- lock spins for a little bit, then gets put to sleep in second phase

